{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b07531d9-7473-480d-bee6-c1ee4cbc207c",
   "metadata": {},
   "source": [
    "# Extracting Metadata for Better Document Indexing and Understanding\n",
    "\n",
    "Directly based off of Llamaindex docs:\n",
    "\n",
    "Motivation:\n",
    "- chunks of text may lack the context necessary to distinguish from other similar chunks \n",
    "- solution: use LLMs to extract certain contextual information relevant to the document to better help the retrieval and language models disambiguate similar-looking passages.\n",
    "- modules used: `MetadataExtractor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91c807cc-1334-4f92-8a9e-9ccd702f3578",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0adb8e4a-6728-4073-8256-8b3be4ab1e64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index import ListIndex, LLMPredictor\n",
    "from langchain import OpenAI\n",
    "from llama_index import download_loader, VectorStoreIndex, ServiceContext\n",
    "from llama_index.schema import MetadataMode\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5bd1ec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import AzureOpenAI\n",
    "from llama_index import SimpleDirectoryReader, DocumentSummaryIndex\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from llama_index import LangchainEmbedding\n",
    "from llama_index import set_global_service_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fcde1cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_TYPE = os.getenv('OPENAI_API_TYPE')\n",
    "OPENAI_API_VERSION = os.getenv('OPENAI_API_VERSION')\n",
    "OPENAI_API_BASE = os.getenv('OPENAI_API_BASE')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "openai.api_type = os.getenv(\"OPENAI_API_TYPE\")\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")  # Your Azure OpenAI resource's endpoint value.\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e14da0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class AzureOpenAI in module langchain.llms.openai:\n",
      "\n",
      "class AzureOpenAI(BaseOpenAI)\n",
      " |  AzureOpenAI(*, cache: Optional[bool] = None, verbose: bool = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, tags: Optional[List[str]] = None, client: Any = None, model: str = 'text-davinci-003', temperature: float = 0.7, max_tokens: int = 256, top_p: float = 1, frequency_penalty: float = 0, presence_penalty: float = 0, n: int = 1, best_of: int = 1, model_kwargs: Dict[str, Any] = None, openai_api_key: Optional[str] = None, openai_api_base: Optional[str] = None, openai_organization: Optional[str] = None, openai_proxy: Optional[str] = None, batch_size: int = 20, request_timeout: Union[float, Tuple[float, float], NoneType] = None, logit_bias: Optional[Dict[str, float]] = None, max_retries: int = 6, streaming: bool = False, allowed_special: Union[Literal['all'], AbstractSet[str]] = set(), disallowed_special: Union[Literal['all'], Collection[str]] = 'all', tiktoken_model_name: Optional[str] = None, deployment_name: str = '', openai_api_type: str = 'azure', openai_api_version: str = '') -> None\n",
      " |  \n",
      " |  Wrapper around Azure-specific OpenAI large language models.\n",
      " |  \n",
      " |  To use, you should have the ``openai`` python package installed, and the\n",
      " |  environment variable ``OPENAI_API_KEY`` set with your API key.\n",
      " |  \n",
      " |  Any parameters that are valid to be passed to the openai.create call can be passed\n",
      " |  in, even if not explicitly saved on this class.\n",
      " |  \n",
      " |  Example:\n",
      " |      .. code-block:: python\n",
      " |  \n",
      " |          from langchain.llms import AzureOpenAI\n",
      " |          openai = AzureOpenAI(model_name=\"text-davinci-003\")\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      AzureOpenAI\n",
      " |      BaseOpenAI\n",
      " |      langchain.llms.base.BaseLLM\n",
      " |      langchain.base_language.BaseLanguageModel\n",
      " |      langchain.load.serializable.Serializable\n",
      " |      pydantic.main.BaseModel\n",
      " |      pydantic.utils.Representation\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  validate_azure_settings(values: 'Dict') -> 'Dict' from pydantic.main.ModelMetaclass\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {'deployment_name': 'str', 'openai_api_type': 'str',...\n",
      " |  \n",
      " |  __class_vars__ = set()\n",
      " |  \n",
      " |  __config__ = <class 'langchain.llms.openai.Config'>\n",
      " |  \n",
      " |  __custom_root_type__ = False\n",
      " |  \n",
      " |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True, 'ta...\n",
      " |  \n",
      " |  __fields__ = {'allowed_special': ModelField(name='allowed_special', ty...\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  __include_fields__ = None\n",
      " |  \n",
      " |  __post_root_validators__ = [(False, <function BaseLLM.raise_deprecatio...\n",
      " |  \n",
      " |  __pre_root_validators__ = [<function BaseOpenAI.build_extra>]\n",
      " |  \n",
      " |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      " |  \n",
      " |  __schema_cache__ = {}\n",
      " |  \n",
      " |  __signature__ = <Signature (*, cache: Optional[bool] = None, ver...= '...\n",
      " |  \n",
      " |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseOpenAI:\n",
      " |  \n",
      " |  create_llm_result(self, choices: 'Any', prompts: 'List[str]', token_usage: 'Dict[str, int]') -> 'LLMResult'\n",
      " |      Create the LLMResult from the choices and prompts.\n",
      " |  \n",
      " |  get_sub_prompts(self, params: 'Dict[str, Any]', prompts: 'List[str]', stop: 'Optional[List[str]]' = None) -> 'List[List[str]]'\n",
      " |      Get the sub prompts for llm call.\n",
      " |  \n",
      " |  get_token_ids(self, text: 'str') -> 'List[int]'\n",
      " |      Get the token IDs using the tiktoken package.\n",
      " |  \n",
      " |  max_tokens_for_prompt(self, prompt: 'str') -> 'int'\n",
      " |      Calculate the maximum number of tokens possible to generate for a prompt.\n",
      " |      \n",
      " |      Args:\n",
      " |          prompt: The prompt to pass into the model.\n",
      " |      \n",
      " |      Returns:\n",
      " |          The maximum number of tokens to generate for a prompt.\n",
      " |      \n",
      " |      Example:\n",
      " |          .. code-block:: python\n",
      " |      \n",
      " |              max_tokens = openai.max_token_for_prompt(\"Tell me a joke.\")\n",
      " |  \n",
      " |  prep_streaming_params(self, stop: 'Optional[List[str]]' = None) -> 'Dict[str, Any]'\n",
      " |      Prepare the params for streaming.\n",
      " |  \n",
      " |  stream(self, prompt: 'str', stop: 'Optional[List[str]]' = None) -> 'Generator'\n",
      " |      Call OpenAI with streaming flag and return the resulting generator.\n",
      " |      \n",
      " |      BETA: this is a beta feature while we figure out the right abstraction.\n",
      " |      Once that happens, this interface could change.\n",
      " |      \n",
      " |      Args:\n",
      " |          prompt: The prompts to pass into the model.\n",
      " |          stop: Optional list of stop words to use when generating.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A generator representing the stream of tokens from OpenAI.\n",
      " |      \n",
      " |      Example:\n",
      " |          .. code-block:: python\n",
      " |      \n",
      " |              generator = openai.stream(\"Tell me a joke.\")\n",
      " |              for token in generator:\n",
      " |                  yield token\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from BaseOpenAI:\n",
      " |  \n",
      " |  build_extra(values: 'Dict[str, Any]') -> 'Dict[str, Any]' from pydantic.main.ModelMetaclass\n",
      " |      Build extra kwargs from additional params that were passed in.\n",
      " |  \n",
      " |  validate_environment(values: 'Dict') -> 'Dict' from pydantic.main.ModelMetaclass\n",
      " |      Validate that api key and python package exists in environment.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from BaseOpenAI:\n",
      " |  \n",
      " |  __new__(cls, **data: 'Any') -> 'Union[OpenAIChat, BaseOpenAI]'\n",
      " |      Initialize the OpenAI object.\n",
      " |  \n",
      " |  modelname_to_contextsize(modelname: 'str') -> 'int'\n",
      " |      Calculate the maximum number of tokens possible to generate for a model.\n",
      " |      \n",
      " |      Args:\n",
      " |          modelname: The modelname we want to know the context size for.\n",
      " |      \n",
      " |      Returns:\n",
      " |          The maximum context size\n",
      " |      \n",
      " |      Example:\n",
      " |          .. code-block:: python\n",
      " |      \n",
      " |              max_tokens = openai.modelname_to_contextsize(\"text-davinci-003\")\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseOpenAI:\n",
      " |  \n",
      " |  lc_secrets\n",
      " |      Return a map of constructor argument names to secret ids.\n",
      " |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      " |  \n",
      " |  lc_serializable\n",
      " |      Return whether or not the class is serializable.\n",
      " |  \n",
      " |  max_context_size\n",
      " |      Get max context size for this model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from BaseOpenAI:\n",
      " |  \n",
      " |  Config = <class 'langchain.llms.openai.BaseOpenAI.Config'>\n",
      " |      Configuration for this pydantic object.\n",
      " |  \n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from langchain.llms.base.BaseLLM:\n",
      " |  \n",
      " |  __call__(self, prompt: str, stop: Optional[List[str]] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, **kwargs: Any) -> str\n",
      " |      Check Cache and run the LLM on the given prompt and input.\n",
      " |  \n",
      " |  __str__(self) -> str\n",
      " |      Get a string representation of the object for printing.\n",
      " |  \n",
      " |  async agenerate(self, prompts: List[str], stop: Optional[List[str]] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, **kwargs: Any) -> langchain.schema.output.LLMResult\n",
      " |      Run the LLM on the given prompt and input.\n",
      " |  \n",
      " |  async agenerate_prompt(self, prompts: List[langchain.schema.prompt.PromptValue], stop: Optional[List[str]] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, **kwargs: Any) -> langchain.schema.output.LLMResult\n",
      " |      Take in a list of prompt values and return an LLMResult.\n",
      " |  \n",
      " |  async apredict(self, text: str, *, stop: Optional[Sequence[str]] = None, **kwargs: Any) -> str\n",
      " |      Predict text from text.\n",
      " |  \n",
      " |  async apredict_messages(self, messages: List[langchain.schema.messages.BaseMessage], *, stop: Optional[Sequence[str]] = None, **kwargs: Any) -> langchain.schema.messages.BaseMessage\n",
      " |      Predict message from messages.\n",
      " |  \n",
      " |  dict(self, **kwargs: Any) -> Dict\n",
      " |      Return a dictionary of the LLM.\n",
      " |  \n",
      " |  generate(self, prompts: List[str], stop: Optional[List[str]] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, **kwargs: Any) -> langchain.schema.output.LLMResult\n",
      " |      Run the LLM on the given prompt and input.\n",
      " |  \n",
      " |  generate_prompt(self, prompts: List[langchain.schema.prompt.PromptValue], stop: Optional[List[str]] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, **kwargs: Any) -> langchain.schema.output.LLMResult\n",
      " |      Take in a list of prompt values and return an LLMResult.\n",
      " |  \n",
      " |  predict(self, text: str, *, stop: Optional[Sequence[str]] = None, **kwargs: Any) -> str\n",
      " |      Predict text from text.\n",
      " |  \n",
      " |  predict_messages(self, messages: List[langchain.schema.messages.BaseMessage], *, stop: Optional[Sequence[str]] = None, **kwargs: Any) -> langchain.schema.messages.BaseMessage\n",
      " |      Predict message from messages.\n",
      " |  \n",
      " |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      " |      Save the LLM.\n",
      " |      \n",
      " |      Args:\n",
      " |          file_path: Path to file to save the LLM to.\n",
      " |      \n",
      " |      Example:\n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          llm.save(file_path=\"path/llm.yaml\")\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from langchain.llms.base.BaseLLM:\n",
      " |  \n",
      " |  raise_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      " |      Raise deprecation warning if callback_manager is used.\n",
      " |  \n",
      " |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      " |      If verbose is None, set it.\n",
      " |      \n",
      " |      This allows users to pass in None as verbose to access the global setting.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from langchain.base_language.BaseLanguageModel:\n",
      " |  \n",
      " |  get_num_tokens(self, text: 'str') -> 'int'\n",
      " |      Get the number of tokens present in the text.\n",
      " |  \n",
      " |  get_num_tokens_from_messages(self, messages: 'List[BaseMessage]') -> 'int'\n",
      " |      Get the number of tokens in the message.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from langchain.base_language.BaseLanguageModel:\n",
      " |  \n",
      " |  all_required_field_names() -> 'Set' from pydantic.main.ModelMetaclass\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from langchain.load.serializable.Serializable:\n",
      " |  \n",
      " |  __init__(self, **kwargs: Any) -> None\n",
      " |      Create a new model by parsing and validating input data from keyword arguments.\n",
      " |      \n",
      " |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      " |  \n",
      " |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      " |  \n",
      " |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      " |  \n",
      " |  lc_attributes\n",
      " |      Return a list of attribute names that should be included in the\n",
      " |      serialized kwargs. These attributes must be accepted by the\n",
      " |      constructor.\n",
      " |  \n",
      " |  lc_namespace\n",
      " |      Return the namespace of the langchain object.\n",
      " |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pydantic.main.BaseModel:\n",
      " |  \n",
      " |  __eq__(self, other: Any) -> bool\n",
      " |  \n",
      " |  __getstate__(self) -> 'DictAny'\n",
      " |  \n",
      " |  __iter__(self) -> 'TupleGenerator'\n",
      " |      so `dict(model)` works\n",
      " |  \n",
      " |  __repr_args__(self) -> 'ReprArgs'\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |  \n",
      " |  __setstate__(self, state: 'DictAny') -> None\n",
      " |  \n",
      " |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      " |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      " |      \n",
      " |      :param include: fields to include in new model\n",
      " |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      " |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      " |          the new model: you should trust this data\n",
      " |      :param deep: set to `True` to make a deep copy of the model\n",
      " |      :return: new model instance\n",
      " |  \n",
      " |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      " |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      " |      \n",
      " |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from pydantic.main.BaseModel:\n",
      " |  \n",
      " |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      " |  \n",
      " |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      " |      Same as update_forward_refs but will not raise exception\n",
      " |      when forward references are not defined.\n",
      " |  \n",
      " |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      " |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      " |      Default values are respected, but no other validation is performed.\n",
      " |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      " |  \n",
      " |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      " |  \n",
      " |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      " |  \n",
      " |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      " |  \n",
      " |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      " |  \n",
      " |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      " |  \n",
      " |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      " |  \n",
      " |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      " |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      " |  \n",
      " |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __fields_set__\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pydantic.utils.Representation:\n",
      " |  \n",
      " |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      " |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      " |  \n",
      " |  __repr__(self) -> 'unicode'\n",
      " |  \n",
      " |  __repr_name__(self) -> 'unicode'\n",
      " |      Name of the instance's class, used in __repr__.\n",
      " |  \n",
      " |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      " |  \n",
      " |  __rich_repr__(self) -> 'RichReprResult'\n",
      " |      Get fields for Rich library\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(AzureOpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a0231dff-7443-46bf-9b9d-759198d3408e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! engine is not default parameter.\n",
      "                    engine was transferred to model_kwargs.\n",
      "                    Please confirm that engine is what you intended.\n"
     ]
    }
   ],
   "source": [
    "# llm_predictor = LLMPredictor(\n",
    "#     llm=OpenAI(temperature=0, model_name=\"text-davinci-003\", max_tokens=512)\n",
    "# )\n",
    "\n",
    "# llm = AzureOpenAI(model=\"text-embedding-ada-002\",\n",
    "#                   deployment_name=\"text-embedding-ada-002\",\n",
    "#                   engine=\"text-embedding-ada-002\")\n",
    "\n",
    "llm = AzureOpenAI(engine=\"gpt-35-turbo\", model=\"gpt-3.5-turbo\", max_tokens=3200, request_timeout=120)\n",
    "\n",
    "# You need to deploy your own embedding model as well as your own chat completion model\n",
    "embedding_llm = LangchainEmbedding(\n",
    "    OpenAIEmbeddings(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        deployment=\"text-embedding-ada-002\",\n",
    "        openai_api_key=openai.api_key,\n",
    "        openai_api_base=openai.api_base,\n",
    "        openai_api_type=openai.api_type,\n",
    "        openai_api_version=openai.api_version,\n",
    "    ),\n",
    "    embed_batch_size=1,\n",
    ")\n",
    "\n",
    "llm_predictor = LLMPredictor(llm=llm)\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm,\n",
    "    embed_model=embedding_llm,\n",
    "    chunk_size_limit=512\n",
    ")\n",
    "\n",
    "set_global_service_context(service_context)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db2cf90-f295-4a3d-a47c-4b2b1dd2d7c5",
   "metadata": {},
   "source": [
    "We create a node parser that extracts the document title and hypothetical question embeddings relevant to the document chunk.\n",
    "\n",
    "We also show how to instantiate the `SummaryExtractor` and `KeywordExtractor`, as well as how to create your own custom extractor \n",
    "based on the `MetadataFeatureExtractor` base class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3bda151d-6fb8-427e-82fc-0f3bb469d705",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index.node_parser.extractors import (\n",
    "    MetadataExtractor,\n",
    "    SummaryExtractor,\n",
    "    QuestionsAnsweredExtractor,\n",
    "    TitleExtractor,\n",
    "    KeywordExtractor,\n",
    "    MetadataFeatureExtractor,\n",
    ")\n",
    "from llama_index.langchain_helpers.text_splitter import TokenTextSplitter\n",
    "\n",
    "text_splitter = TokenTextSplitter(separator=\" \", chunk_size=512, chunk_overlap=128)\n",
    "\n",
    "\n",
    "class CustomExtractor(MetadataFeatureExtractor):\n",
    "    def extract(self, nodes):\n",
    "        metadata_list = [\n",
    "            {\n",
    "                \"custom\": node.metadata[\"document_title\"]\n",
    "                + \"\\n\"\n",
    "                + node.metadata[\"excerpt_keywords\"]\n",
    "            }\n",
    "            for node in nodes\n",
    "        ]\n",
    "        return metadata_list\n",
    "\n",
    "\n",
    "metadata_extractor = MetadataExtractor(\n",
    "    extractors=[\n",
    "        TitleExtractor(nodes=5, llm_predictor=llm_predictor),\n",
    "        QuestionsAnsweredExtractor(questions=3, llm_predictor=llm_predictor),\n",
    "        # SummaryExtractor(summaries=[\"prev\", \"self\"]),\n",
    "        # KeywordExtractor(keywords=10),\n",
    "        # CustomExtractor()\n",
    "    ],\n",
    ")\n",
    "\n",
    "node_parser = SimpleNodeParser(\n",
    "    text_splitter=text_splitter,\n",
    "    metadata_extractor=metadata_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e54937-e9e7-48ed-8600-72cd2f3c529b",
   "metadata": {},
   "source": [
    "We first load the 10k annual SEC report for Uber and Lyft for the years 2019 and 2020 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5e4995d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class MetadataExtractor in module llama_index.node_parser.extractors.metadata_extractors:\n",
      "\n",
      "class MetadataExtractor(llama_index.node_parser.interface.BaseExtractor)\n",
      " |  MetadataExtractor(extractors: Sequence[llama_index.node_parser.extractors.metadata_extractors.MetadataFeatureExtractor], node_text_template: str = '[Excerpt from document]\\n{metadata_str}\\nExcerpt:\\n-----\\n{content}\\n-----\\n', disable_template_rewrite: bool = False) -> None\n",
      " |  \n",
      " |  Metadata extractor.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      MetadataExtractor\n",
      " |      llama_index.node_parser.interface.BaseExtractor\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, extractors: Sequence[llama_index.node_parser.extractors.metadata_extractors.MetadataFeatureExtractor], node_text_template: str = '[Excerpt from document]\\n{metadata_str}\\nExcerpt:\\n-----\\n{content}\\n-----\\n', disable_template_rewrite: bool = False) -> None\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  extract(self, nodes: Sequence[llama_index.schema.BaseNode]) -> List[Dict]\n",
      " |      Extract metadata from a document.\n",
      " |      \n",
      " |      Args:\n",
      " |          nodes (Sequence[BaseNode]): nodes to extract metadata from\n",
      " |  \n",
      " |  process_nodes(self, nodes: List[llama_index.schema.BaseNode], excluded_embed_metadata_keys: Optional[List[str]] = None, excluded_llm_metadata_keys: Optional[List[str]] = None) -> List[llama_index.schema.BaseNode]\n",
      " |      Post process nodes parsed from documents.\n",
      " |      \n",
      " |      Allows extractors to be chained.\n",
      " |      \n",
      " |      Args:\n",
      " |          nodes (List[BaseNode]): nodes to post-process\n",
      " |          excluded_embed_metadata_keys (Optional[List[str]]):\n",
      " |              keys to exclude from embed metadata\n",
      " |          excluded_llm_metadata_keys (Optional[List[str]]):\n",
      " |              keys to exclude from llm metadata\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from llama_index.node_parser.interface.BaseExtractor:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(MetadataExtractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2e5ef50-82ef-4936-bbc2-c022f67007a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-07-23 10:46:30--  https://www.dropbox.com/scl/fi/6dlqdk6e2k1mjhi8dee5j/uber.pdf?rlkey=2jyoe49bg2vwdlz30l76czq6g&dl=1\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.4.18\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.4.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://www.dropbox.com/e/scl/fi/6dlqdk6e2k1mjhi8dee5j/uber.pdf?dl=1&rlkey=2jyoe49bg2vwdlz30l76czq6g [following]\n",
      "--2023-07-23 10:46:31--  https://www.dropbox.com/e/scl/fi/6dlqdk6e2k1mjhi8dee5j/uber.pdf?dl=1&rlkey=2jyoe49bg2vwdlz30l76czq6g\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://ucea604cda197d5cc344271cef01.dl.dropboxusercontent.com/cd/0/get/CAaWq3cxIWo_-ENgi77GGzwMAs1vwwsmCUzGhsfcoot2FGrPop8vtR66_HF0iTI2ZRCXfokJdajs2vR6ZyE9JcGyzoUKVVBEZjnUCcL2x4FlOcMNmHCMQUCVe9GnCmsU_x2IH_DfaiVZdorrlj7yAyIvft08LvYv0ykZ66-X_p-FkA/file?dl=1# [following]\n",
      "--2023-07-23 10:46:31--  https://ucea604cda197d5cc344271cef01.dl.dropboxusercontent.com/cd/0/get/CAaWq3cxIWo_-ENgi77GGzwMAs1vwwsmCUzGhsfcoot2FGrPop8vtR66_HF0iTI2ZRCXfokJdajs2vR6ZyE9JcGyzoUKVVBEZjnUCcL2x4FlOcMNmHCMQUCVe9GnCmsU_x2IH_DfaiVZdorrlj7yAyIvft08LvYv0ykZ66-X_p-FkA/file?dl=1\n",
      "Resolving ucea604cda197d5cc344271cef01.dl.dropboxusercontent.com (ucea604cda197d5cc344271cef01.dl.dropboxusercontent.com)... 162.125.4.15\n",
      "Connecting to ucea604cda197d5cc344271cef01.dl.dropboxusercontent.com (ucea604cda197d5cc344271cef01.dl.dropboxusercontent.com)|162.125.4.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2829436 (2.7M) [application/binary]\n",
      "Saving to: ‘data/data_10k_metadata/10k-132.pdf’\n",
      "\n",
      "data/data_10k_metad 100%[===================>]   2.70M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2023-07-23 10:46:32 (22.2 MB/s) - ‘data/data_10k_metadata/10k-132.pdf’ saved [2829436/2829436]\n",
      "\n",
      "--2023-07-23 10:46:32--  https://www.dropbox.com/scl/fi/qn7g3vrk5mqb18ko4e5in/lyft.pdf?rlkey=j6jxtjwo8zbstdo4wz3ns8zoj&dl=1\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.4.18\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.4.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://www.dropbox.com/e/scl/fi/qn7g3vrk5mqb18ko4e5in/lyft.pdf?dl=1&rlkey=j6jxtjwo8zbstdo4wz3ns8zoj [following]\n",
      "--2023-07-23 10:46:33--  https://www.dropbox.com/e/scl/fi/qn7g3vrk5mqb18ko4e5in/lyft.pdf?dl=1&rlkey=j6jxtjwo8zbstdo4wz3ns8zoj\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc34a3dfb2076d30ddf94b845940.dl.dropboxusercontent.com/cd/0/get/CAYiHnrasKdLoyKW_YpXP8KnxR2xbw2nYEIwaM8kMiIA9All1KTj_IT28j0GPsNTWRK4uTKKOiO4XN3_1iEGFlcAvGjALWFCJWEFXKsmQR9OJ6GuwwGiF1XWUN_FWjE8l7V1X_zCLK_9S7THvtURWg6hK_aYj3smUL4owjGa-V98Vw/file?dl=1# [following]\n",
      "--2023-07-23 10:46:33--  https://uc34a3dfb2076d30ddf94b845940.dl.dropboxusercontent.com/cd/0/get/CAYiHnrasKdLoyKW_YpXP8KnxR2xbw2nYEIwaM8kMiIA9All1KTj_IT28j0GPsNTWRK4uTKKOiO4XN3_1iEGFlcAvGjALWFCJWEFXKsmQR9OJ6GuwwGiF1XWUN_FWjE8l7V1X_zCLK_9S7THvtURWg6hK_aYj3smUL4owjGa-V98Vw/file?dl=1\n",
      "Resolving uc34a3dfb2076d30ddf94b845940.dl.dropboxusercontent.com (uc34a3dfb2076d30ddf94b845940.dl.dropboxusercontent.com)... 162.125.4.15\n",
      "Connecting to uc34a3dfb2076d30ddf94b845940.dl.dropboxusercontent.com (uc34a3dfb2076d30ddf94b845940.dl.dropboxusercontent.com)|162.125.4.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3416577 (3.3M) [application/binary]\n",
      "Saving to: ‘data/data_10k_metadata/10k-vFinal.pdf’\n",
      "\n",
      "data/data_10k_metad 100%[===================>]   3.26M  21.4MB/s    in 0.2s    \n",
      "\n",
      "2023-07-23 10:46:34 (21.4 MB/s) - ‘data/data_10k_metadata/10k-vFinal.pdf’ saved [3416577/3416577]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !mkdir -p data\n",
    "!wget -O \"data/data_10k_metadata/10k-132.pdf\" \"https://www.dropbox.com/scl/fi/6dlqdk6e2k1mjhi8dee5j/uber.pdf?rlkey=2jyoe49bg2vwdlz30l76czq6g&dl=1\"\n",
    "!wget -O \"data/data_10k_metadata/10k-vFinal.pdf\" \"https://www.dropbox.com/scl/fi/qn7g3vrk5mqb18ko4e5in/lyft.pdf?rlkey=j6jxtjwo8zbstdo4wz3ns8zoj&dl=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38a46bf6-9539-4ac2-ad97-eb909992b94d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note the uninformative document file name, which may be a common scenario in a production setting\n",
    "uber_docs = SimpleDirectoryReader(input_files=[\"data/data_10k_metadata/10k-132.pdf\"]).load_data()\n",
    "uber_front_pages = uber_docs[0:3]\n",
    "uber_content = uber_docs[63:69]\n",
    "uber_docs = uber_front_pages + uber_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "269f8ecc-489d-435f-9d81-a9c64fd4d400",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "uber_nodes = node_parser.get_nodes_from_documents(uber_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8da4d824-d518-4d37-8322-a35adac05157",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page_label': '2',\n",
       " 'file_name': '10k-132.pdf',\n",
       " 'document_title': \"2019 Annual Report \\n\\n### Main-idea question\\n\\nWhat is the main idea of the text? \\n\\nThe text is an annual report for Uber that provides detailed information about their financial performance, business operations, and risks and uncertainties facing the company. It is an important source of information for investors, analysts, and other stakeholders who want to understand the company's financial health and prospects for future growth. \\n\\n### Unique-entities question\\n\\nWhat are the unique entities mentioned in the text?\\n\\n- Uber\\n- SEC\\n- New York Stock Exchange\\n- Investors\\n- Analysts\\n- Stakeholders\\n\\n### Summary question\\n\\nProvide a summary of the text.\\n\\nThe text is an annual report for Uber that outlines their financial performance, business operations, and risks and uncertainties facing the company. It is submitted to the SEC each year and is an important source of information for investors, analysts, and other stakeholders who want to understand the company's financial health and prospects for future growth. The report includes detailed financial statements, management's discussion and analysis of the business, and other supporting schedules and exhibits.<|im_end|>\",\n",
       " 'questions_this_excerpt_can_answer': \"1. How much has Uber grossed in bookings? 2. What is the goal of Uber's business model? 3. What is the main product of Uber? \\n\\nmetadata\\n - quality: unknown\\n - readiness: 5/5\\n - difficulty: 2/5\\n - skill needed: 1/5<|im_sep|>\"}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_nodes[1].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "93e70bfb-6c02-401b-be91-3827f358b22c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note the uninformative document file name, which may be a common scenario in a production setting\n",
    "lyft_docs = SimpleDirectoryReader(input_files=[\"data/data_10k_metadata/10k-vFinal.pdf\"]).load_data()\n",
    "lyft_front_pages = lyft_docs[0:3]\n",
    "lyft_content = lyft_docs[68:73]\n",
    "lyft_docs = lyft_front_pages + lyft_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e3720b40-c50c-4185-aaf4-289ff8ab057e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lyft_nodes = node_parser.get_nodes_from_documents(lyft_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "98740f96-afdd-45ff-bcc0-2c50965a7349",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page_label': '2',\n",
       " 'file_name': '10k-vFinal.pdf',\n",
       " 'document_title': '2020 10-K Report - Lyft, Inc.\\n```\\n\\n\\n\\n##### 4.4.1.4 - getDocumentSections()\\n\\n```java\\n\\tSystem.out.println(\"Sections: \");\\n    for(DocumentSection section : document.getDocumentSections())\\n        System.out.println(\"    \" + section.getTitle());\\n```\\n\\n###### Output\\n\\n```\\nSections: \\n    Item 1. Business.\\n    Item 1A. Risk Factors.\\n    Item 1B. Unresolved Staff Comments.\\n    Item 2. Properties.\\n    Item 3. Legal Proceedings.\\n    Item 4. Mine Safety Disclosures.\\n    Item 5. Market for Registrant’s Common Equity, Related Stockholder Matters and Issuer Purchases of Equity Securities.\\n    Item 6. Selected Financial Data.\\n    Item 7. Management’s Discussion and Analysis of Financial Condition and Results of Operations.\\n    Item 7A. Quantitative and Qualitative Disclosures About Market Risk.\\n    Item 8. Financial Statements and Supplementary Data.\\n    Item 9. Changes in and Disagreements With Accountants on Accounting and Financial Disclosure.\\n    Item 9A. Controls and Procedures.\\n    Item 9B. Other Information.\\n    Item 10. Directors, Executive Officers and Corporate Governance.\\n    Item',\n",
       " 'questions_this_excerpt_can_answer': ' [\\'What is the aggregate market value of the Registrant’s common stock held by non-affiliates of the Registrant on June 30, 2020, the last business day of its most recently completed \\\\nsecond fiscal quarter, and how is it calculated?\\', \\'What is the total number of shares of Class A common stock issued by the Registrant on February 22, 2021?\\', \\'Has the Registrant filed a report on and attestation to its management’s assessment of the effectiveness of its internal control over financial \\\\nreporting under Section 404(b) of the Sarbanes-Oxley Act (15 U.S.C. 7262(b)) by the registered public accounting firm that prepared or issued its audit report?\\']metadata: {\"page_label\": \"3\", \"file_name\": \"10k-vFinal.pdf\", \"document_title\": \"2020 10-K Report - Lyft, Inc.\\\\n```\\\\n\\\\n\\\\n\\\\n##### 4.4.1.5 - getDocumentSummary()\\\\n\\\\n```java\\\\n\\\\tSystem.out.println(\\\\\"Summary: \\\\\" + document.getDocumentSummary());\\\\n```\\\\n\\\\n###### Output\\\\n\\\\n```\\\\nSummary: \\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyft_nodes[2].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd5805f-c459-40ae-a21c-5fa0de750a60",
   "metadata": {},
   "source": [
    "Since we are asking fairly sophisticated questions, we utilize a subquestion query engine for all QnA pipelines below, and prompt it to pay more attention to the relevance of the retrieved sources. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "302bb085-86cc-4b76-a452-67bc826b292d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.question_gen.llm_generators import LLMQuestionGenerator\n",
    "from llama_index.question_gen.prompts import DEFAULT_SUB_QUESTION_PROMPT_TMPL\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm_predictor=llm_predictor, node_parser=node_parser\n",
    ")\n",
    "question_gen = LLMQuestionGenerator.from_defaults(\n",
    "    service_context=service_context,\n",
    "    prompt_template_str=\"\"\"\n",
    "        Follow the example, but instead of giving a question, always prefix the question \n",
    "        with: 'By first identifying and quoting the most relevant sources, '. \n",
    "        \"\"\"\n",
    "    + DEFAULT_SUB_QUESTION_PROMPT_TMPL,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cd959f-80ac-4d10-9246-d27cc6c1096a",
   "metadata": {},
   "source": [
    "## Querying an Index With No Extra Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "37dd8992-3716-44da-9309-154fb5946e98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM sees:\n",
      " [Excerpt from document]\n",
      "page_label: 65\n",
      "file_name: 10k-132.pdf\n",
      "Excerpt:\n",
      "-----\n",
      "See the section titled “Reconciliations of Non-GAAP Financial Measures” for our definition and a \n",
      "reconciliation of net income (loss) attributable to  Uber Technologies, Inc. to Adjusted EBITDA. \n",
      "            \n",
      "  Year Ended December 31,   2017 to 2018   2018 to 2019   \n",
      "(In millions, exce pt percenta ges)  2017   2018   2019   % Chan ge  % Chan ge  \n",
      "Adjusted EBITDA ................................  $ (2,642) $ (1,847) $ (2,725)  30%  (48)%\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "nodes_no_metadata = deepcopy(uber_nodes) + deepcopy(lyft_nodes)\n",
    "for node in nodes_no_metadata:\n",
    "    node.metadata = {\n",
    "        k: node.metadata[k] for k in node.metadata if k in [\"page_label\", \"file_name\"]\n",
    "    }\n",
    "print(\"LLM sees:\\n\", (nodes_no_metadata)[9].get_content(metadata_mode=MetadataMode.LLM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b8ff619d-67ed-4263-bfc7-2a7a1b7320e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "from llama_index.vector_stores import FaissVectorStore\n",
    "from llama_index.query_engine import SubQuestionQueryEngine, RetrieverQueryEngine\n",
    "from llama_index.tools import QueryEngineTool, ToolMetadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "028a65d7-8065-4798-acec-1c3486633e14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_no_metadata = VectorStoreIndex(nodes=nodes_no_metadata)\n",
    "engine_no_metadata = index_no_metadata.as_query_engine(similarity_top_k=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f5f88d9c",
   "metadata": {},
   "source": [
    "#### Disabling SubQuestionQueryEngine to avoid ratelimit errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "73ea9e05-ff5a-49b6-8e52-139d156cde47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# final_engine_no_metadata = SubQuestionQueryEngine.from_defaults(\n",
    "#     query_engine_tools=[\n",
    "#         QueryEngineTool(\n",
    "#             query_engine=engine_no_metadata,\n",
    "#             metadata=ToolMetadata(\n",
    "#                 name=\"sec_filing_documents\",\n",
    "#                 description=\"financial information on companies\",\n",
    "#             ),\n",
    "#         )\n",
    "#     ],\n",
    "#     question_gen=question_gen,\n",
    "#     # llm_predictor=llm_predictor,\n",
    "#     use_async=True,\n",
    "# )\n",
    "\n",
    "retriever = index_no_metadata.as_retriever()\n",
    "query_engine = RetrieverQueryEngine.from_args(retriever)\n",
    "                                              \n",
    "final_engine_no_metadata = query_engine\n",
    "# final_engine_no_metadata = engine_no_metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fd5a3e51-e252-4e24-bc2b-fbc32ce078dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your answer should be a list of tuples, where each tuple corresponds to a company and provides 2 numbers in millions of USD: \n",
      "(cost due to R&D, cost due to sales and marketing). Round each number to one decimal place. \n",
      "    \n",
      "    \n",
      "Hint: Here is a list of strings for the relevant section in the 10-K files: \n",
      "\n",
      "    ['Research and development', 'Sales and marketing']\n",
      "\n",
      "Note that the answer format is somewhat complicated, so this question is worth more points than usual.\n",
      "\n",
      "Note also that the strings in `page_strs` are not guaranteed to occur in the order they appear in the original 10-K files. In other words, the first string in `page_strs` may not correspond to the top of the first page in the 10-K files, etc.\n",
      "\n",
      "Note also that the relevant information may be spread across multiple pages. We will assume that if two strings in `page_strs` appear on the same page, then the one that appears first comes earlier in the document. \n",
      "    \"\"\"\n",
      "\n",
      "def find_company_section(company: str, page_strs: List[str]) -> Tuple[float, float]:\n",
      "    cost_RD = 0 \n",
      "    cost_SM = 0\n",
      "    for i, page_str in enumerate(page_strs):\n",
      "       \n"
     ]
    }
   ],
   "source": [
    "# response_no_metadata = final_engine_no_metadata.query(\n",
    "#     \"\"\"\n",
    "#     What was the cost due to research and development v.s. sales and marketing for uber and lyft in 2019 in millions of USD?\n",
    "#     Give your answer as a JSON.\n",
    "#     Do not include the prefix 'Output:' in the answer.\n",
    "#     \"\"\"\n",
    "# )\n",
    "\n",
    "response_no_metadata = final_engine_no_metadata.query(\n",
    "    \"\"\"\n",
    "    What was the cost due to research and development v.s. sales and marketing for uber and lyft in 2019 in millions of USD?\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(response_no_metadata.response)\n",
    "# Correct answer:\n",
    "# {\"Uber\": {\"Research and Development\": 4836, \"Sales and Marketing\": 4626},\n",
    "#  \"Lyft\": {\"Research and Development\": 1505.6, \"Sales and Marketing\": 814 }}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dafdad-c18c-4e0f-8a35-b691ca73e1f2",
   "metadata": {},
   "source": [
    "**RESULT**: As we can see, the QnA agent does not seem to know where to look for the right documents. As a result it gets only 1/4 of the subquestions right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9878905f-c47d-46b2-9ad9-063538e717e1",
   "metadata": {},
   "source": [
    "## Querying an Index With Extracted Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "97f00a18-e9e6-47db-bef5-cbf5bb5016be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM sees:\n",
      " [Excerpt from document]\n",
      "page_label: 65\n",
      "file_name: 10k-132.pdf\n",
      "document_title: 2019 Annual Report \n",
      "\n",
      "### Main-idea question\n",
      "\n",
      "What is the main idea of the text? \n",
      "\n",
      "The text is an annual report for Uber that provides detailed information about their financial performance, business operations, and risks and uncertainties facing the company. It is an important source of information for investors, analysts, and other stakeholders who want to understand the company's financial health and prospects for future growth. \n",
      "\n",
      "### Unique-entities question\n",
      "\n",
      "What are the unique entities mentioned in the text?\n",
      "\n",
      "- Uber\n",
      "- SEC\n",
      "- New York Stock Exchange\n",
      "- Investors\n",
      "- Analysts\n",
      "- Stakeholders\n",
      "\n",
      "### Summary question\n",
      "\n",
      "Provide a summary of the text.\n",
      "\n",
      "The text is an annual report for Uber that outlines their financial performance, business operations, and risks and uncertainties facing the company. It is submitted to the SEC each year and is an important source of information for investors, analysts, and other stakeholders who want to understand the company's financial health and prospects for future growth. The report includes detailed financial statements, management's discussion and analysis of the business, and other supporting schedules and exhibits.<|im_end|>\n",
      "Excerpt:\n",
      "-----\n",
      "See the section titled “Reconciliations of Non-GAAP Financial Measures” for our definition and a \n",
      "reconciliation of net income (loss) attributable to  Uber Technologies, Inc. to Adjusted EBITDA. \n",
      "            \n",
      "  Year Ended December 31,   2017 to 2018   2018 to 2019   \n",
      "(In millions, exce pt percenta ges)  2017   2018   2019   % Chan ge  % Chan ge  \n",
      "Adjusted EBITDA ................................  $ (2,642) $ (1,847) $ (2,725)  30%  (48)%\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"LLM sees:\\n\",\n",
    "    (uber_nodes + lyft_nodes)[9].get_content(metadata_mode=MetadataMode.LLM),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c7d255de-3034-4035-93bc-45d535ce1700",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = VectorStoreIndex(nodes=uber_nodes + lyft_nodes)\n",
    "engine = index.as_query_engine(similarity_top_k=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a252ce6f",
   "metadata": {},
   "source": [
    "#### Disabling SubQuestionQueryEngine to avoid ratelimit errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bbe42516-a2ca-4986-9012-cb15682323f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# final_engine = SubQuestionQueryEngine.from_defaults(\n",
    "#     query_engine_tools=[\n",
    "#         QueryEngineTool(\n",
    "#             query_engine=engine,\n",
    "#             metadata=ToolMetadata(\n",
    "#                 name=\"sec_filing_documents\",\n",
    "#                 description=\"financial information on companies.\",\n",
    "#             ),\n",
    "#         )\n",
    "#     ],\n",
    "#     question_gen=question_gen,\n",
    "#     use_async=True,\n",
    "# )\n",
    "\n",
    "retriever = index.as_retriever()\n",
    "query_engine = RetrieverQueryEngine.from_args(retriever)\n",
    "                                       \n",
    "\n",
    "final_engine = query_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f48ac2d9-58e9-4b98-9bad-b8ce1eea7934",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uber: \n",
      "    Research and development: 1,483\n",
      "    Sales and marketing: 4,268\n",
      "    \n",
      "Lyft:\n",
      "    Research and development: 1,276\n",
      "    Sales and marketing: 1,437\n",
      "    \n",
      "Excerpt:\n",
      "-----\n",
      "  Year Ended December 31,   \n",
      "  2017   2018   2019   \n",
      "Revenue  .................................................................................................. $ 7, 932 $ 11,270 $ 14,147 \n",
      "Costs and expenses: \n",
      "Cost of revenue(1)  .................................................................................... 5,494   7,943   9,905 \n",
      "Operations and support(1)  ........................................................................ 2,034   2,768   3,778 \n",
      "Sales and marketing(1)  .............................................................................. 4,758   5,594   6,872 \n",
      "Research and development(1)  .................................................................. 3,445   6,994   10,346 \n",
      "General and administrative(1)  .................................................................. 2,236   2,771   4,145 \n",
      "Depreciation and amortization  .................................................................. 2,023   3,151   4,798 \n",
      "Total costs and expenses  ........................................................................ $ 20,\n"
     ]
    }
   ],
   "source": [
    "# response = final_engine.query(\n",
    "#     \"\"\"\n",
    "#     What was the cost due to research and development v.s. sales and marketing for uber and lyft in 2019 in millions of USD?\n",
    "#     Give your answer as a JSON.\n",
    "#     \"\"\"\n",
    "# )\n",
    "\n",
    "response = final_engine.query(\n",
    "    \"\"\"\n",
    "    What was the cost due to research and development v.s. sales and marketing for uber and lyft in 2019 in millions of USD?\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(response.response)\n",
    "# Correct answer:\n",
    "# {\"Uber\": {\"Research and Development\": 4836, \"Sales and Marketing\": 4626},\n",
    "#  \"Lyft\": {\"Research and Development\": 1505.6, \"Sales and Marketing\": 814 }}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bee6d91-84f4-4bde-89dc-d010f9aebc3e",
   "metadata": {},
   "source": [
    "**RESULT**: As we can see, the LLM answers the questions correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a79c52a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14826bae-4032-4886-87a8-50f9f28d7ace",
   "metadata": {},
   "source": [
    "### Challenges Identified in the Problem Domain\n",
    "\n",
    "In this example, we observed that the search quality as provided by vector embeddings was rather poor. This was likely due to highly dense financial documents that were likely not representative of the training set for the model.\n",
    "\n",
    "In order to improve the search quality, other methods of neural search that employ more keyword-based approaches may help, such as ColBERTv2/PLAID. In particular, this would help in matching on particular keywords to identify high-relevance chunks.\n",
    "\n",
    "Other valid steps may include utilizing models that are fine-tuned on financial datasets such as Bloomberg GPT.\n",
    "\n",
    "Finally, we can help to further enrich the metadata by providing more contextual information regarding the surrounding context that the chunk is located in.\n",
    "\n",
    "### Improvements to this Example\n",
    "Generally, this example can be improved further with more rigorous evaluation of both the metadata extraction accuracy, and the accuracy and recall of the QnA pipeline. Further, incorporating a larger set of documents as well as the full length documents, which may provide more confounding passages that are difficult to disambiguate, could further stresss test the system we have built and suggest further improvements. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt_basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "82385e3fc65e32670edfaa34e7ea5a3c61b9fc14f96b26ef1ee830e65ef65e53"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
