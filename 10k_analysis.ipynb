{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from llama_index.llms import AzureOpenAI\n",
    "from llama_index import LangchainEmbedding\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "from llama_index import GPTVectorStoreIndex, LLMPredictor, PromptHelper\n",
    "import logging\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_TYPE = os.getenv('OPENAI_API_TYPE')\n",
    "OPENAI_API_VERSION = os.getenv('OPENAI_API_VERSION')\n",
    "OPENAI_API_BASE = os.getenv('OPENAI_API_BASE')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "openai.api_type = os.getenv(\"OPENAI_API_TYPE\")\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")  # Your Azure OpenAI resource's endpoint value.\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azure\n"
     ]
    }
   ],
   "source": [
    "print(os.getenv(\"OPENAI_API_TYPE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    stream=sys.stdout, level=logging.INFO\n",
    ")  # logging.DEBUG for more verbose output\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-07-16 16:52:15--  https://www.dropbox.com/s/948jr9cfs7fgj99/UBER.zip?dl=1\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.4.18\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.4.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /s/dl/948jr9cfs7fgj99/UBER.zip [following]\n",
      "--2023-07-16 16:52:15--  https://www.dropbox.com/s/dl/948jr9cfs7fgj99/UBER.zip\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc22a8628412f805c791a4c3db9c.dl.dropboxusercontent.com/cd/0/get/B_8zaL9CSz6R1bE0MTP9jhm19WiMVuwO4wvXWXD54ZyRg7J01UaJlvv5BDnuTRyARjnFhZJeuUj6KiVZOuDj5442DQdfjQCjCu6yixEyXh8nhrT5TpPa2M5j4n50LtcIUoRwUYNhnvgWmX0zMtiApj6zxIOzv-G_jPxoxk3iiYibLg/file?dl=1# [following]\n",
      "--2023-07-16 16:52:15--  https://uc22a8628412f805c791a4c3db9c.dl.dropboxusercontent.com/cd/0/get/B_8zaL9CSz6R1bE0MTP9jhm19WiMVuwO4wvXWXD54ZyRg7J01UaJlvv5BDnuTRyARjnFhZJeuUj6KiVZOuDj5442DQdfjQCjCu6yixEyXh8nhrT5TpPa2M5j4n50LtcIUoRwUYNhnvgWmX0zMtiApj6zxIOzv-G_jPxoxk3iiYibLg/file?dl=1\n",
      "Resolving uc22a8628412f805c791a4c3db9c.dl.dropboxusercontent.com (uc22a8628412f805c791a4c3db9c.dl.dropboxusercontent.com)... 162.125.4.15\n",
      "Connecting to uc22a8628412f805c791a4c3db9c.dl.dropboxusercontent.com (uc22a8628412f805c791a4c3db9c.dl.dropboxusercontent.com)|162.125.4.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1820227 (1.7M) [application/binary]\n",
      "Saving to: ‘data_10k/UBER.zip’\n",
      "\n",
      "data_10k/UBER.zip   100%[===================>]   1.74M  7.27MB/s    in 0.2s    \n",
      "\n",
      "2023-07-16 16:52:16 (7.27 MB/s) - ‘data_10k/UBER.zip’ saved [1820227/1820227]\n",
      "\n",
      "Archive:  data_10k/UBER.zip\n",
      "   creating: data_10k/UBER/\n",
      "  inflating: data_10k/UBER/UBER_2021.html  \n",
      "  inflating: data_10k/__MACOSX/UBER/._UBER_2021.html  \n",
      "  inflating: data_10k/UBER/UBER_2020.html  \n",
      "  inflating: data_10k/__MACOSX/UBER/._UBER_2020.html  \n",
      "  inflating: data_10k/UBER/UBER_2019.html  \n",
      "  inflating: data_10k/__MACOSX/UBER/._UBER_2019.html  \n",
      "  inflating: data_10k/UBER/UBER_2022.html  \n",
      "  inflating: data_10k/__MACOSX/UBER/._UBER_2022.html  \n"
     ]
    }
   ],
   "source": [
    "# download files\n",
    "!mkdir data_10k\n",
    "!wget https://www.dropbox.com/s/948jr9cfs7fgj99/UBER.zip?dl=1 -O data_10k/UBER.zip\n",
    "!unzip data_10k/UBER.zip -d data_10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set text wrapping\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "def set_css():\n",
    "  display(HTML('''\n",
    "  <style>\n",
    "    pre {\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "  </style>\n",
    "  '''))\n",
    "get_ipython().events.register('pre_run_cell', set_css)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index import download_loader, GPTVectorStoreIndex\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unstructured (from -r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 1))\n",
      "  Downloading unstructured-0.8.1-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 8.9 MB/s eta 0:00:001\n",
      "\u001b[?25hCollecting nltk (from -r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 2))\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 11.7 MB/s eta 0:00:00\n",
      "\u001b[?25hCollecting chardet (from unstructured->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 1))\n",
      "  Downloading chardet-5.1.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 199.1/199.1 kB 5.7 MB/s eta 0:00:00\n",
      "\u001b[?25hCollecting filetype (from unstructured->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 1))\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Collecting lxml (from unstructured->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 1))\n",
      "  Downloading lxml-4.9.3.tar.gz (3.6 MB)\n",
      "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 13.4 MB/s eta 0:00:00\n",
      "\u001b[?25h  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting msg-parser (from unstructured->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 1))\n",
      "  Downloading msg_parser-1.2.0-py2.py3-none-any.whl (101 kB)\n",
      "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.8/101.8 kB 3.1 MB/s eta 0:00:00\n",
      "\u001b[?25hCollecting openpyxl (from unstructured->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 1))\n",
      "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 250.0/250.0 kB 5.6 MB/s eta 0:00:00\n",
      "\u001b[?25hRequirement already satisfied: pandas in /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages (from unstructured->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 1)) (2.0.3)\n",
      "Collecting pdf2image (from unstructured->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 1))\n",
      "  Downloading pdf2image-1.16.3-py3-none-any.whl (11 kB)\n",
      "Collecting pdfminer.six (from unstructured->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 1))\n",
      "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.6/5.6 MB 8.1 MB/s eta 0:00:0024\n",
      "\u001b[?25hCollecting pillow (from unstructured->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 1))\n",
      "  Downloading Pillow-10.0.0-cp310-cp310-macosx_10_10_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.4/3.4 MB 12.8 MB/s eta 0:00:00\n",
      "\u001b[?25hCollecting pypandoc (from unstructured->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 1))\n",
      "  Downloading pypandoc-1.11-py3-none-any.whl (20 kB)\n",
      "Collecting python-docx (from unstructured->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 1))\n",
      "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
      "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.6/5.6 MB 13.2 MB/s eta 0:00:00\n",
      "\u001b[?25h  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting python-pptx (from unstructured->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 1))\n",
      "  Downloading python-pptx-0.6.21.tar.gz (10.1 MB)\n",
      "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.1/10.1 MB 13.2 MB/s eta 0:00:00\n",
      "\u001b[?25h  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting python-magic (from unstructured->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 1))\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Collecting markdown (from unstructured->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 1))\n",
      "  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 93.9/93.9 kB 3.0 MB/s eta 0:00:00\n",
      "\u001b[?25hRequirement already satisfied: requests in /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages (from unstructured->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 1)) (2.31.0)\n",
      "Collecting tabulate (from unstructured->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 1))\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Collecting xlrd (from unstructured->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 1))\n",
      "  Downloading xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n",
      "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 96.5/96.5 kB 2.7 MB/s eta 0:00:00\n",
      "\u001b[?25hRequirement already satisfied: click in /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages (from nltk->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 2)) (8.1.3)\n",
      "Collecting joblib (from nltk->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 2))\n",
      "  Downloading joblib-1.3.1-py3-none-any.whl (301 kB)\n",
      "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 302.0/302.0 kB 7.3 MB/s eta 0:00:00\n",
      "\u001b[?25hRequirement already satisfied: regex>=2021.8.3 in /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages (from nltk->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 2)) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages (from nltk->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 2)) (4.65.0)\n",
      "Collecting olefile>=0.46 (from msg-parser->unstructured->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 1))\n",
      "  Downloading olefile-0.46.zip (112 kB)\n",
      "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 112.2/112.2 kB 4.2 MB/s eta 0:00:00\n",
      "\u001b[?25h  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting et-xmlfile (from openpyxl->unstructured->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 1))\n",
      "  Using cached et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages (from pandas->unstructured->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages (from pandas->unstructured->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages (from pandas->unstructured->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages (from pandas->unstructured->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 1)) (1.25.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages (from pdfminer.six->unstructured->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 1)) (3.1.0)\n",
      "Collecting cryptography>=36.0.0 (from pdfminer.six->unstructured->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 1))\n",
      "  Downloading cryptography-41.0.2-cp37-abi3-macosx_10_12_x86_64.whl (2.8 MB)\n",
      "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.8/2.8 MB 12.3 MB/s eta 0:00:00\n",
      "\u001b[?25hCollecting XlsxWriter>=0.5.7 (from python-pptx->unstructured->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 1))\n",
      "  Downloading XlsxWriter-3.1.2-py3-none-any.whl (153 kB)\n",
      "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 153.0/153.0 kB 4.4 MB/s eta 0:00:00\n",
      "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages (from requests->unstructured->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages (from requests->unstructured->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 1)) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages (from requests->unstructured->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 1)) (2023.5.7)\n",
      "Collecting cffi>=1.12 (from cryptography>=36.0.0->pdfminer.six->unstructured->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 1))\n",
      "  Downloading cffi-1.15.1-cp310-cp310-macosx_10_9_x86_64.whl (179 kB)\n",
      "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 179.2/179.2 kB 5.3 MB/s eta 0:00:00\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->unstructured->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 1)) (1.16.0)\n",
      "Collecting pycparser (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured->-r /Users/yashdixit/opt/anaconda3/envs/gpt_basic/lib/python3.10/site-packages/llama_index/readers/llamahub_modules/file/unstructured/requirements.txt (line 1))\n",
      "  Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "Building wheels for collected packages: lxml, python-docx, python-pptx, olefile\n",
      "  Building wheel for lxml (setup.py): started\n",
      "  Building wheel for lxml (setup.py): still running...\n",
      "  Building wheel for lxml (setup.py): finished with status 'done'\n",
      "  Created wheel for lxml: filename=lxml-4.9.3-cp310-cp310-macosx_10_9_x86_64.whl size=1655402 sha256=aff97a9b11ac496e1d87abedf9b1b94275447b00772b9a8c50cbf481f94aaf59\n",
      "  Stored in directory: /Users/yashdixit/Library/Caches/pip/wheels/38/0b/56/fd5ffdd76481c9220a131ff39258963d8384599f0109b688d0\n",
      "  Building wheel for python-docx (setup.py): started\n",
      "  Building wheel for python-docx (setup.py): finished with status 'done'\n",
      "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184490 sha256=62cf51301f404a22fe20642aa562b2ab6d0f5aa4565b5d6ae6148fd500739cd3\n",
      "  Stored in directory: /Users/yashdixit/Library/Caches/pip/wheels/80/27/06/837436d4c3bd989b957a91679966f207bfd71d358d63a8194d\n",
      "  Building wheel for python-pptx (setup.py): started\n",
      "  Building wheel for python-pptx (setup.py): finished with status 'done'\n",
      "  Created wheel for python-pptx: filename=python_pptx-0.6.21-py3-none-any.whl size=470935 sha256=02ffef3d3e7b1ccc9d21349c6c2cbe38059fe57e74e0d1d6bfa12987ae901c07\n",
      "  Stored in directory: /Users/yashdixit/Library/Caches/pip/wheels/ea/dd/74/01b3ec7256a0800b99384e9a0f7620e358afc3a51a59bf9b49\n",
      "  Building wheel for olefile (setup.py): started\n",
      "  Building wheel for olefile (setup.py): finished with status 'done'\n",
      "  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35417 sha256=11bc165f6da3930ad8f890918f2bbd2b94e8771d8f29e76f830ce22510e126fa\n",
      "  Stored in directory: /Users/yashdixit/Library/Caches/pip/wheels/02/39/c0/9eb1f7a42b4b38f6f333b6314d4ed11c46f12a0f7b78194f0d\n",
      "Successfully built lxml python-docx python-pptx olefile\n",
      "Installing collected packages: filetype, XlsxWriter, xlrd, tabulate, python-magic, pypandoc, pycparser, pillow, olefile, markdown, lxml, joblib, et-xmlfile, chardet, python-pptx, python-docx, pdf2image, openpyxl, nltk, msg-parser, cffi, cryptography, pdfminer.six, unstructured\n",
      "Successfully installed XlsxWriter-3.1.2 cffi-1.15.1 chardet-5.1.0 cryptography-41.0.2 et-xmlfile-1.1.0 filetype-1.2.0 joblib-1.3.1 lxml-4.9.3 markdown-3.4.3 msg-parser-1.2.0 nltk-3.8.1 olefile-0.46 openpyxl-3.1.2 pdf2image-1.16.3 pdfminer.six-20221105 pillow-10.0.0 pycparser-2.21 pypandoc-1.11 python-docx-0.8.11 python-magic-0.4.27 python-pptx-0.6.21 tabulate-0.9.0 unstructured-0.8.1 xlrd-2.0.1\n"
     ]
    }
   ],
   "source": [
    "UnstructuredReader = download_loader(\"UnstructuredReader\", refresh_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yashdixit/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/yashdixit/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:unstructured:Reading document from string ...\n",
      "Reading document from string ...\n",
      "INFO:unstructured:Reading document ...\n",
      "Reading document ...\n",
      "INFO:unstructured:Reading document from string ...\n",
      "Reading document from string ...\n",
      "INFO:unstructured:Reading document ...\n",
      "Reading document ...\n",
      "INFO:unstructured:Reading document from string ...\n",
      "Reading document from string ...\n",
      "INFO:unstructured:Reading document ...\n",
      "Reading document ...\n",
      "INFO:unstructured:Reading document from string ...\n",
      "Reading document from string ...\n",
      "INFO:unstructured:Reading document ...\n",
      "Reading document ...\n"
     ]
    }
   ],
   "source": [
    "loader = UnstructuredReader()\n",
    "doc_set = {}\n",
    "all_docs = []\n",
    "years = [2022, 2021, 2020, 2019]\n",
    "for year in years:\n",
    "    year_docs = loader.load_data(file=Path(f'./data_10k/UBER/UBER_{year}.html'), split_documents=False)\n",
    "    # insert year metadata into each year\n",
    "    for d in year_docs:\n",
    "        d.extra_info = {\"year\": year}\n",
    "    doc_set[year] = year_docs\n",
    "    all_docs.extend(year_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm = AzureOpenAI(engine=\"gpt-35-turbo\", model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# You need to deploy your own embedding model as well as your own chat completion model\n",
    "embedding_llm = LangchainEmbedding(\n",
    "    OpenAIEmbeddings(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        deployment=\"text-embedding-ada-002\",\n",
    "        openai_api_key=openai.api_key,\n",
    "        openai_api_base=openai.api_base,\n",
    "        openai_api_type=openai.api_type,\n",
    "        openai_api_version=openai.api_version,\n",
    "    ),\n",
    "    embed_batch_size=1,\n",
    ")\n",
    "\n",
    "# documents = SimpleDirectoryReader(\"data\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:llama_index.indices.service_context:chunk_size_limit is deprecated, please specify chunk_size instead\n",
      "chunk_size_limit is deprecated, please specify chunk_size instead\n"
     ]
    }
   ],
   "source": [
    "from llama_index import set_global_service_context\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm,\n",
    "    embed_model=embedding_llm,\n",
    "    chunk_size_limit=512\n",
    ")\n",
    "\n",
    "set_global_service_context(service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize simple vector indices + global vector index\n",
    "# NOTE: don't run this cell if the indices are already loaded! \n",
    "index_set = {}\n",
    "for year in years:\n",
    "    cur_index = VectorStoreIndex.from_documents(doc_set[year], service_context=service_context)\n",
    "    index_set[year] = cur_index\n",
    "    # cur_index.save_to_disk(f'index_{year}.json')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### ONLY RUN THIS IF YOU WANT TO ASK GLOBAL QUESTIONS ACROSS ALL YEARS, AS MENTIONED BELOW\n",
    "# global_index = VectorStoreIndex.from_documents(all_docs, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = (index_set[2020].as_query_engine(similarity_top_k=3)).query(\"What were some of the biggest risk factors in 2020?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some of the biggest risk factors in 2020 were the adverse impact of the COVID-19 pandemic on the business and operations, including reduced demand for mobility offerings, changes in travel behavior and demand, and the need for remote work arrangements. Other risk factors included privacy, cybersecurity, and fraud risks, regulatory challenges, workforce reductions, and changes to pricing models. The uncertainty and unpredictability of the pandemic's impact on future business operations, liquidity, financial condition, and results of operations were also significant risk factors.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ASK GLOBAL QUESTIONS ACROSS ALL YEARS\n",
    "\n",
    "# risk_query_str = \"What are some of the biggest risk factors in each year?\"\n",
    "# response = (global_index.as_query_engine(similarity_top_k=3)).query(risk_query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt_basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82385e3fc65e32670edfaa34e7ea5a3c61b9fc14f96b26ef1ee830e65ef65e53"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
